{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/mathematical_foundations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1ad25a4-3413-40be-a2ab-6a09423aed11",
      "metadata": {
        "id": "c1ad25a4-3413-40be-a2ab-6a09423aed11"
      },
      "source": [
        "# Mathematical foundations\n",
        "A neural network (NN) is a computational model of a function based on a set of connected units, called neurons, that can learn a mapping between the inputs from a domain space and the outputs in the same or in different domain.   \n",
        "\n",
        "A unit of a NN is represented as a nonlinear function of an affine transformation of a set of inputs\n",
        "\n",
        "$$z = \\sigma(b + \\sum_i w_i*x_i)$$\n",
        "\n",
        "where $x_i$ represent the inputs, b is a bias value like the intercept of a linear function, z the output, $w_i$ the parameters and $\\sigma$ is the activation function that enable the NN to represent nonlinear functions. The units o a NN are organized in layers. Each layer contains a number of units. Each unit of a layer receives its inputs from the units in the previous layer and sends the result of its computation to the units in the next layer. A NN can be represented as a set of nested functions, e.g. for three layers h,g,f\n",
        "\n",
        "$$\\hat y(x, w) = f(g(h(x, w_h), w_g), w_f)$$\n",
        "\n",
        "The NN can be trained, in a supervised approach, using a set of example pairs of inputs and related outputs. The goal is to learn the NN units' parameters so that the error, that is the difference between the network's output $\\hat y(x)$ and the real value y, is as small as possible. The error to be minimized is called the loss function and can be written as\n",
        "\n",
        "$$ℒ = \\frac{1}{2}||\\hat y(x, w) - y(x)||^2$$\n",
        "\n",
        "Finding the NN parameters values that result in the minimum of the error function for any input x is an optimization problem that can be solved by computing the gradient of the function y(x, w), with respect to the parameters w, and using it to reduce the error\n",
        "\n",
        "$$w_{i+1} = w_i - γ∇_wℒ$$\n",
        "\n",
        "This optimization algorithm is called gradient descent. It is performed in backpropagation, starting from the output and going back, through each layer of the network, computing the derivatives at each unit. The derivatives are computed using the chain rule in the operations described in the NN's computational graph that represents the operations to be performed at each unit. The NN computational graph is a directed acyclic graph that is executed automatically by deep learning frameworks such as Tensorflow and PyTorch.    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da93dd9-03b5-4133-91c0-c585906b2546",
      "metadata": {
        "id": "4da93dd9-03b5-4133-91c0-c585906b2546"
      },
      "source": [
        "## Types of data\n",
        "A NN can only handle numerical values that can be provided as\n",
        "\n",
        "* Tabular data\n",
        "* Images\n",
        "* Sequences (time series)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65e6e9e-20ee-4729-bc53-880247920ec1",
      "metadata": {
        "id": "b65e6e9e-20ee-4729-bc53-880247920ec1"
      },
      "source": [
        "## Tensors and tensor operations\n",
        "In a NN the input data and the network parameters are handled as tensors, that is multidimensional numerical arrays. The operations that can be performed on a tensor (unit operation) or pair of tensors are\n",
        "\n",
        "* dot (tensor product)\n",
        "* addition\n",
        "* element-wise\n",
        "* broadcasting\n",
        "* reshaping\n",
        "* scaling\n",
        "* rotation\n",
        "* translation\n",
        "* derivative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea135446-0d3a-481a-9a84-f0cef6853fae",
      "metadata": {
        "id": "ea135446-0d3a-481a-9a84-f0cef6853fae"
      },
      "source": [
        "## Loss functions and optimizers\n",
        "Many other loss functions and optimization algorithms are available that might be more or less performant but all based on computing derivatives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6504cf4-f72f-4813-b949-80ad8a2b49a7",
      "metadata": {
        "id": "f6504cf4-f72f-4813-b949-80ad8a2b49a7"
      },
      "source": [
        "## Stochastic gradient descent, mini batch, and batch training loops\n",
        "The update of the network parameters is performed within a training loop in a forward and backward pass. The amount of data to be used in each loops can be one single data point, extracted randomly from the training set and for this reason is called stochastic gradient descent. If the training set is large the stochastic gradient descent may take a long time to process all the data. Another approach is to use a small set of samples, called a mini-batch, and update the parameters using the mean of the values. One other approach is to use the full training set to compute the parametrs update, called batch, for each training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8324da33-2919-4d74-bfcb-21de65fa6ba1",
      "metadata": {
        "id": "8324da33-2919-4d74-bfcb-21de65fa6ba1"
      },
      "source": [
        "## Epochs\n",
        "A training loop that is perfomed on all the training data is called epoch. The training phase of a NN can consist usually of several epochs till the accuracy of the model achieves a maximum."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4098c84-4c28-4e91-9403-b80799791a2b",
      "metadata": {
        "id": "f4098c84-4c28-4e91-9403-b80799791a2b"
      },
      "source": [
        "## NN design, training, and performance evaluation\n",
        "The implementation of a NN model can be divided in:\n",
        "\n",
        "1. Design (number of layers, number of units per layer, activation function)\n",
        "2. Compilation (loss function, optimizer, performance metrics)\n",
        "3. Fitting (number of epochs, batch size)\n",
        "4. Evaluation (mean squared error, accuracy)\n",
        "\n",
        "The evaluation metrics are used with validation and test sets, to test a model.\n",
        "For instance, the mean squared error ([MSE](https://en.wikipedia.org/wiki/Mean_squared_error)) is a performance metrics used in regression tasks. Given N samples in the test set we have\n",
        "\n",
        "$$MSE = \\frac{1}{N} \\sum_{i=0}^N (Y_i - \\hat Y_i)^2$$\n",
        "\n",
        "where $Y_i$ are the observations and $\\hat Y_i$ the predicted values. [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision) is used in classification tasks and is defined as a ratio\n",
        "\n",
        "\n",
        "$$Accuracy = \\frac{number\\ of\\ correct\\ classifications}{number\\ of\\ classifications} = \\frac {TP + TN}{TP + TN + FP + FN}$$\n",
        "\n",
        "\n",
        "where TP = true positives, TN = true negatives, FP = false positives, and FN = false negatives.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659ced5c-c103-4b0d-bfb8-6fd8779a0add",
      "metadata": {
        "id": "659ced5c-c103-4b0d-bfb8-6fd8779a0add"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}