{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/deep_learning_for_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f667f06-5a62-4ce6-bc78-f9fd0d96175a",
      "metadata": {
        "id": "6f667f06-5a62-4ce6-bc78-f9fd0d96175a"
      },
      "source": [
        "# Deep learning for text\n",
        "In this notebook we will use deep learning algorithms to perform some tasks on text. Common tasks are: text classification, content filtering, sentiment analysis, translation, text summarization, language modeling. Since deep learning models are differentiable functions that can only process tensors of numbers we have to transform text into numerical tensors. The steps to transform text into numbers are\n",
        "\n",
        "1. Text standardization\n",
        "2. Tokenization\n",
        "3. Convert the tokens into numerical arrays\n",
        "\n",
        "In the first step we perform the same kind of transformations used to build a search engine: lower case, remove punctuation, word stemming. The words left represent the tokens, elements of a \"clean\" vocabulary. We can also build token made of two words, called bigram, or more words called N-gram. The number of tokens N defines the dimensionality of a space where each token represents a dimension and a text can be represented as vector in such space. We can define a metric is such a space so that we can measure the distance between two sequences of tokens. Depending on the task at hand, we might need to process the tokens in the order in which they appear in the text. In this case we will build a sequence model. If our task doesn't need the order of the tokens we will build a bag-of-words model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540a8b78-6869-4a0f-82c6-b01e808cc1bc",
      "metadata": {
        "id": "540a8b78-6869-4a0f-82c6-b01e808cc1bc"
      },
      "source": [
        "## Bag-of-words models\n",
        "We will use the [IMDB dataset]('https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) to train our bag-of-words model for sentiment analysis, that is a kind of text classification. The dataset contains 50k movie reviews. We download the dataset and extract the files into a folder. The dataset contains two subfolders train/ and test/ each containing 25k reviews split into two subfolders pos/ and neg/ with 12500 txt files. Each file contains a short text, the content of the review. The name of the file is created from the review's unique identifier and the score given to the movie. A score equal or higher than 7 is positive, a score equal or lower than 4 is negative. This same example is available for PyTorch in [another repository](https://github.com/luigiselmi/machine_learning_notes/blob/main/pml3/sentiment_analysis.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12d88618-a75c-405a-bb56-fae698e09738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12d88618-a75c-405a-bb56-fae698e09738",
        "outputId": "66cc9b10-ef20-4319-da88-4f1ac092abf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-27 20:33:32 URL:https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz [84125825/84125825] -> \"./data/aclImdb_v1.tar.gz\" [1]\n"
          ]
        }
      ],
      "source": [
        "!wget -nv 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz' -P './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d94aab15-0e4c-4ef9-beab-f2eb529ce992",
      "metadata": {
        "id": "d94aab15-0e4c-4ef9-beab-f2eb529ce992"
      },
      "outputs": [],
      "source": [
        "!tar -xf data/aclImdb_v1.tar.gz -C data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cf722b0b-3366-4fbc-971d-33636d4c78fc",
      "metadata": {
        "id": "cf722b0b-3366-4fbc-971d-33636d4c78fc"
      },
      "outputs": [],
      "source": [
        "!rm -r data/aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3c2491-d13c-4849-b566-f55dc207ad1d",
      "metadata": {
        "id": "2d3c2491-d13c-4849-b566-f55dc207ad1d"
      },
      "source": [
        "We print the content of one review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e9d10772-828c-4207-b2da-52dd2a6aea69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9d10772-828c-4207-b2da-52dd2a6aea69",
        "outputId": "84f76f8b-1dd2-43c1-ba2e-5bec5267dc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!cat data/aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb335163-cabd-43bb-ad2e-9e498c800021",
      "metadata": {
        "id": "fb335163-cabd-43bb-ad2e-9e498c800021"
      },
      "source": [
        "We use 20% of the training data for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d3182c20-454d-4aad-a0c1-bd5cb003c8bd",
      "metadata": {
        "id": "d3182c20-454d-4aad-a0c1-bd5cb003c8bd"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "base_dir = pathlib.Path(\"data/aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname, val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5559307-9bd1-41d6-81f5-43d5a2880567",
      "metadata": {
        "id": "f5559307-9bd1-41d6-81f5-43d5a2880567"
      },
      "source": [
        "We create three datasets for train, validation and test using the utility function text_dataset_from_directory() that returns a [Dataset](https://keras.io/api/data_loading/text/) object that asynchronouly fetches the data from a source data folder that has a structure like\n",
        "\n",
        "main_directory/  \n",
        "...class_a/  \n",
        "......a_text_1.txt  \n",
        "......a_text_2.txt  \n",
        "...class_b/  \n",
        "......b_text_1.txt  \n",
        "......b_text_2.txt  \n",
        "\n",
        "Each dataset contains a number of batches with 32 reviews with the respective numerical labels starting from 0 for the first class, in our case negative review, and 1 for the positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ee5b14c8-cf51-48f6-88c8-48545f281f0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee5b14c8-cf51-48f6-88c8-48545f281f0d",
        "outputId": "2dc47645-6bce-490f-a857-5b93855b0fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "train_ds = keras.utils.text_dataset_from_directory('data/aclImdb/train', batch_size=batch_size)\n",
        "val_ds = keras.utils.text_dataset_from_directory('data/aclImdb/val', batch_size=batch_size)\n",
        "test_ds = keras.utils.text_dataset_from_directory('data/aclImdb/test', batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d4a0fd7-61f0-49c4-867a-c1198358c6b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d4a0fd7-61f0-49c4-867a-c1198358c6b5",
        "outputId": "972975fa-fac0-4fff-dec9-1ab7b3514a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches for training: 625\n",
            "Number of batches for validation: 157\n",
            "Number of batches for test: 782\n"
          ]
        }
      ],
      "source": [
        "print('Number of batches for training: {:d}'.format(len(train_ds)))\n",
        "print('Number of batches for validation: {:d}'.format(len(val_ds)))\n",
        "print('Number of batches for test: {:d}'.format(len(test_ds)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)\n",
        "  print(\"inputs.dtype:\", inputs.dtype)\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ],
      "metadata": {
        "id": "4-SSBbhpTMrk",
        "outputId": "ba521bbc-92e7-43f2-a767-5267aa0e19d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4-SSBbhpTMrk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b'Excellent episode movie ala Pulp Fiction. 7 days - 7 suicides. It doesnt get more depressing than this. Movie rating: 8/10 Music rating: 10/10', shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the set of the most common 20000 tokens with only one word, aka unigrams, to define a space of the same dimensionality to represent each review as a vector in this space"
      ],
      "metadata": {
        "id": "gPpWQd2tnTUq"
      },
      "id": "gPpWQd2tnTUq"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(max_tokens=20000, output_mode=\"multi_hot\",)\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_1gram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "binary_1gram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "binary_1gram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "NcQvaLeleArj"
      },
      "id": "NcQvaLeleArj",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "  loss=\"binary_crossentropy\",\n",
        "  metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "OXa087W_mSUq"
      },
      "id": "OXa087W_mSUq",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [\n",
        "  keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n",
        "  save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "1xcI_yJypWRY",
        "outputId": "aaac88b1-1fd6-4559-daa3-2735aef035ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "id": "1xcI_yJypWRY",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(binary_1gram_train_ds.cache(),\n",
        "#          validation_data=binary_1gram_val_ds.cache(),\n",
        "#          epochs=10,\n",
        "#          callbacks=callbacks)"
      ],
      "metadata": {
        "id": "RuFKmP3lpikQ"
      },
      "id": "RuFKmP3lpikQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-04Azs8pvpA"
      },
      "id": "O-04Azs8pvpA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}