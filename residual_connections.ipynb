{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXpkUsTFzBE0CSXhFoxaaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/residual_connections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual connections\n",
        "Deep neural networks are affected by the *vanishing gradients* problem for which the parameters become increasingly smaller. One solution to avoid such problem is to use a shortcut, that is to add the input to the output of a block of one or more layers. Residual connections have been introduced in the paper \"[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\" by He et al.\n",
        "![residual connection](https://github.com/luigiselmi/dl_tensorflow/blob/main/images/residual_connection.jpg?raw=1)"
      ],
      "metadata": {
        "id": "AsazO6OeSqpT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PtuHFowNQok-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the output of a block of convolutional layers can change. For instance, more filters can be added while the height and width of the filters can shrink if a MaxPooling layer is added to a convolutional layer. In order to add the input tensor to the output they have to have the same shape.   "
      ],
      "metadata": {
        "id": "ycIFGWHsYRka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBHoUYO7QwiN",
        "outputId": "1bc0b699-643d-4d60-8e02-b34f73a9eed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we add a block to the model that doubles the number of filters"
      ],
      "metadata": {
        "id": "k1YclJA2ZjLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnJ9VME7RA07",
        "outputId": "2a5f68e8-5940-4c0e-e17f-03ad525d498c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we can use a 1x1 convolutional layer without activation function that will simply project the input to the same number of 2D arrays"
      ],
      "metadata": {
        "id": "cb5qsfBzbxmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residual = layers.Conv2D(64, 1)(residual)\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDkm_Zy6SEKa",
        "outputId": "22327efb-b299-448f-ccfe-de120ecc2e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the input can be added to each filter"
      ],
      "metadata": {
        "id": "duem1OREdD77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.add([x, residual])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEbK7S3pST85",
        "outputId": "f88254dc-afd2-4080-e4cd-97805ad0aee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we see the case for which also the height and width of the filters changes"
      ],
      "metadata": {
        "id": "6W7Mm51SdefX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "residual.shape"
      ],
      "metadata": {
        "id": "pIbE7jNKSaJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09a7c43-cc9a-49c8-d36c-53ba02e0e0fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance we double the number of filters like before and we also reduce the size of each filter"
      ],
      "metadata": {
        "id": "ffZ1wv-Dew6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBDUF0khd5MK",
        "outputId": "0234441c-4cf0-4c09-918f-5db405ded96e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we use again a 1x1 convolutional layer without activation function and with stride = 2 to match the size of the filters."
      ],
      "metadata": {
        "id": "YMRvGW-RfIvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIL4xILneZSq",
        "outputId": "93000694-d03f-410f-e1b1-48db70f249f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can add the input tensor to the output."
      ],
      "metadata": {
        "id": "W-mCCTS4gIXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.add([x, residual])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d9ph5fzfFLI",
        "outputId": "b1108db7-1c98-483d-adbb-e2a454302778"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An example of ConvNet with residual blocks\n",
        "We build a simple convolutional network using three residual blocks, each containing two convolutional layers.   "
      ],
      "metadata": {
        "id": "xi3WJhZ7icze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, pooling=False):\n",
        "    residual = x\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    if pooling:\n",
        "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "    elif filters != residual.shape[-1]:\n",
        "        residual = layers.Conv2D(filters, 1)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "    return x"
      ],
      "metadata": {
        "id": "uO945Vx1gGC9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We double the number of filters of each block, that is of each convolutional layer inside the block, and change their size in two blocks."
      ],
      "metadata": {
        "id": "oqxnz1t3jeIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = residual_block(x, filters=32, pooling=True)\n",
        "x = residual_block(x, filters=64, pooling=True)\n",
        "x = residual_block(x, filters=128, pooling=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4URf9kSAh5ru",
        "outputId": "089a2ea9-0762-4cbd-f2ae-9be98bdc36dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)       (None, 32, 32, 3)            0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)           896       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 32)           9248      ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 32)           128       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 32)           0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)           18496     ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)           36928     ['conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_8[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 8, 8, 64)             2112      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 8, 8, 64)             0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)            73856     ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 128)            8320      ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 8, 8, 128)            0         ['conv2d_11[0][0]',           \n",
            "                                                                     'conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 128)                  0         ['add_4[0][0]']               \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    129       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 297697 (1.14 MB)\n",
            "Trainable params: 297697 (1.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlU3cIiDiHVe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}