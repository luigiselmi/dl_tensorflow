{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/zK4wPC0+WiqSqmTwtu54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras\n",
        "Keras is a high level API on top of Tensorflow."
      ],
      "metadata": {
        "id": "triexj5vyPW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "FmcBAshGyUuz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers\n",
        "A deep neural network is a graph of layers. The most simple topology is a stack of layers. There are many different types of layers. Layers differ mainly for the algorithms that is applied to the input tensors to produce its output tensor. Other settings of a layer are the number of units and the actvation function. The number of weights depends on the number of units of the layer and on the number of inputs. We can define a Python class to instantiate a layer. In a dense layer all the inputs are connected to all the layer's units. The build() method in the example define the weights matrix and the bias vector with random initialization. The call() method computes the vector product between the weights matrix and the inputs and then applies the activation function passed as argument to the class constructor.  "
      ],
      "metadata": {
        "id": "0lhFUhFbs-zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TqwQ-pU9s8z-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class SimpleDense(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, activation=None):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer='zeros')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = tf.matmul(inputs, self.W) + self.b\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can instantiate a layer, for example with 32 units without specifying the number of outputs since it can be inferred from the number of inputs of the next layer. A sequence of two layers are used like two matrices to be multiplied so if the shape of the first layer is (n x m) the shape of the second one must be (m x p) and so on."
      ],
      "metadata": {
        "id": "DHAUfNRV0JYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "mydense_layer = SimpleDense(units=32, activation=tf.nn.relu)\n",
        "input_tensor = tf.ones(shape=(1, 784))\n",
        "output_tensor = mydense_layer(input_tensor)\n",
        "print(output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ji-W84jv8_F",
        "outputId": "fe1d08c4-ff99-4091-82be-281635214ce1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLgy6cb1xpJz",
        "outputId": "443170b4-f8cf-415a-e439-bee447f30e15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 784), dtype=float32, numpy=\n",
              "array([[1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9WWoYocylal"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}