{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+VBIK9cOVHR8o8fpyxSsl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/convnet_best_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Deep Learning for Computer Vsion - ConvNet Architecture Best Practices\n",
        "In this notebook we present three architectural changes for convolutional layers that can improve the efficiency and the results of standard convolutional networks. The main changes are\n",
        "\n",
        "1. Residual blocks\n",
        "2. Batch normalization\n",
        "3. Separable convolution\n",
        "\n",
        "Finally we will implement all thse changes in a small version of the Xception architecture and will use the model on the cat and dogs dataset to compare its performance with the standard convolutional network model used in the notebook [*Deep Learning for Computer Vision*](computer_vision.ipynb)"
      ],
      "metadata": {
        "id": "ONo-_D12pRgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Residual connections\n",
        "Deep neural networks are affected by the *vanishing gradients* problem for which the parameters become increasingly smaller. One solution to avoid such problem is to use a shortcut, that is to add the input to the output of a block of one or more layers. Residual connections have been introduced in the paper \"[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\" by He et al.\n",
        "![residual connection](https://github.com/luigiselmi/dl_tensorflow/blob/main/images/residual_connection.jpg?raw=1)"
      ],
      "metadata": {
        "id": "dTpBqI4ZpGf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "4UcdtJ1Nr0OG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the output of a block of convolutional layers can change. For instance, more filters can be added while the height and width of the filters can shrink if a MaxPooling layer is added to a convolutional layer. In order to add the input tensor to the output they have to have the same shape."
      ],
      "metadata": {
        "id": "dkGeyJ1XrdrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPaQSaPDsGCm",
        "outputId": "2c0f4f63-e449-4781-b65e-1eed845ee1b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we add a block to the model that doubles the number of filters"
      ],
      "metadata": {
        "id": "-vnMSN6SsMvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHFO7AM3sUkV",
        "outputId": "90d39c86-8acf-4f55-ad56-9eca568562dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we can use a 1x1 convolutional layer without activation function that will simply project the input to the same number of 2D arrays"
      ],
      "metadata": {
        "id": "rtlXND0osaoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residual = layers.Conv2D(64, 1)(residual)\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kbvghalsjBk",
        "outputId": "243f8a78-d607-425b-a5f1-f8fb97d5a34d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the input can be added to each filter"
      ],
      "metadata": {
        "id": "k6wV742zsyOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.add([x, residual])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4W-4yFls4u5",
        "outputId": "69cb34f5-5c98-4d9b-b99e-17c469afd8a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we see the case for which also the height and width of the filters changes"
      ],
      "metadata": {
        "id": "FcUyKLOgtAyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOJ2ORTdtH6e",
        "outputId": "ad716b2d-df6f-4a4c-c604-75c9fd8acaab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30, 30, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance we double the number of filters like before and we also reduce the size of each filter"
      ],
      "metadata": {
        "id": "5ued6YhQtMRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foOtxM25tSI8",
        "outputId": "06f876cd-6c01-49ef-ec94-3a5c73ccd405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we use again a 1x1 convolutional layer without activation function and with stride = 2 to match the size of the filters."
      ],
      "metadata": {
        "id": "hDKNi6MRtYCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
        "residual.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV3Uv3oxte5n",
        "outputId": "34e8ce87-4a15-4f17-c71e-decbd99308ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can add the input tensor to the output."
      ],
      "metadata": {
        "id": "In6JosNQtmdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.add([x, residual])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MajUZe86trBD",
        "outputId": "794a4c90-b51e-4dc6-865f-ae3b5357a4ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 15, 15, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An example of ConvNet with residual blocks\n",
        "We build a simple convolutional network using three residual blocks, each containing two convolutional layers.   "
      ],
      "metadata": {
        "id": "7u8-LAxJtwry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, pooling=False):\n",
        "    residual = x\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    if pooling:\n",
        "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "    elif filters != residual.shape[-1]:\n",
        "        residual = layers.Conv2D(filters, 1)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "    return x"
      ],
      "metadata": {
        "id": "m-4cu-czt4_v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We double the number of filters of each block, that is of each convolutional layer inside the block, and change their size in two blocks."
      ],
      "metadata": {
        "id": "epQ5F4fet9BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = residual_block(x, filters=32, pooling=True)\n",
        "x = residual_block(x, filters=64, pooling=True)\n",
        "x = residual_block(x, filters=128, pooling=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hy6zkJ7uCE8",
        "outputId": "7a59072a-2ddc-48c0-b700-21ba211696de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)       (None, 32, 32, 3)            0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)           896       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)           9248      ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)           128       ['rescaling[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 32)           0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)           18496     ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_10[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 64)             2112      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 8, 8, 64)             0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 128)            73856     ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 128)            8320      ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 8, 8, 128)            0         ['conv2d_13[0][0]',           \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 128)                  0         ['add_4[0][0]']               \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    129       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 297697 (1.14 MB)\n",
            "Trainable params: 297697 (1.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch normalization\n",
        "Data normalization is usually applied in machine learning algorithms where the input feautures have values of different order of magnitude, generally speaking, when their distribution is very different. Usually we subtract the mean to the input data and divide the result by the standard deviation. In classic machine learning algorithms is assumed that such transformation is enough to avoid problems. In deep neural networks where the data may pass through several layers with nonlinear activation functions we cannot assume that the output values, or distribution, of a layer or block of layers will stay within a certain range. A batch normalization layer, e.g. *BatchNormalization* in Keras, is a layer that can be added after a layer or block to normalize the data during training and inference time. The type of normalization is the same as discussed above. During the training phase the normalization is based on the current batch of data. At inference time the input data is normalized according to the exponential moving average and to the standard deviation of the batches seen during training. Batch normalization improves the gradient propagation and therefore deeper networks as the residual connections. A BatchNormalization layer can be added before the activation function as shown in the following code snippet. Another improvement is to remove the bias since the batch normalization will move the values around a zero mean distribution.    "
      ],
      "metadata": {
        "id": "zELiSlVrmoWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "h0XZkruCrkIg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y6ZRDKKCmTnf"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "\n",
        "x = layers.Conv2D(32, 3, use_bias=False)(x) # the bias can be removed since the normalization will remove it anyway\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x) # apply the activation function after the nbatch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch normalization is used in many deep learning architectures such as ResNet, EfficientNet, Xception."
      ],
      "metadata": {
        "id": "-wKzRHEqLjM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separable convolutions\n",
        "In a standard convolutional layer the filters are applied to each input feature map. The number of learnable parameters, without the bias, is given by\n",
        "\n",
        "$$p_l = f_{l-1} \\times k_l \\times k_l \\times f_l $$\n",
        "\n",
        "so e.g. for a $3 \\times 3$ kernel size, 64 input feature maps and 64 filters the number of parameters is 36864. if we assume that the feature maps are independent, that is there is no correlation between them, we might apply each filter to only one feature map and add them together. In this case the number of learnable parameters is\n",
        "\n",
        "$$p_{l} = f_{l-1} \\times k_l \\times k_l + f_{l-1} \\times f_l$$\n",
        "\n",
        "So for the exampe above the number of paameters would be 4672, a reduction of almost a factor 8 in the number of parameters."
      ],
      "metadata": {
        "id": "YQbmkgIYZAcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Xception architecture\n",
        "We implement a small version of the Xception architecture that uses the improvement discussed so far: residual blocks, batch normalization, and separable convolutions. We use the model with the cats and dogs dataset. Since these are RGB images where each channel is higly correlated with the others, the architecture start with a standard depth-wise convolutional layer followed by blocks containning separable convolutional layers (*SeparableConv2D* layer in Keras).  "
      ],
      "metadata": {
        "id": "o7WXr6BHfAfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the dataset from Kaggle as in the [*Deep Learning for Computer Vision*](computer_vision.ipynb) notebook. We need to upload our token in order to access the dataset."
      ],
      "metadata": {
        "id": "6JzCJVwXjXHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "8tZnA_MujVZ4",
        "outputId": "1609ea14-076c-4e55-b69c-376210086ffc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32d99eb1-08a0-44a2-90e3-5e1774b40ba1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32d99eb1-08a0-44a2-90e3-5e1774b40ba1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"lselmi\",\"key\":\"c8a6ca5d3e0efc3c981490a3cbb4bb98\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /root/.kaggle"
      ],
      "metadata": {
        "id": "ha8IsTkPkL25"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv kaggle.json /root/.kaggle/"
      ],
      "metadata": {
        "id": "3pW2oGLTkRc_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4zfEHKQkYSJ",
        "outputId": "114e49eb-4da7-443c-8af3-8c33389275bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 812M/812M [00:16<00:00, 27.4MB/s]\n",
            "100% 812M/812M [00:16<00:00, 50.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "czAHsj0hkflj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/train.zip"
      ],
      "metadata": {
        "id": "o2wIMLzlkk13"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/train/ -type f | grep cat |wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSgPY0D9kuzw",
        "outputId": "e0592cbf-2fde-4a15-d0d5-08cf1c02b6a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/train/ -type f | grep dog |wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S08vuIUTky_J",
        "outputId": "0962cb68-997e-4d86-94af-d928f0768cc8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "original_dir = pathlib.Path(\"/content/train/\")\n",
        "new_base_dir = pathlib.Path(\"/content/cats_vs_dogs_small\")"
      ],
      "metadata": {
        "id": "5hXNYSuym1T8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\"\n",
        "            for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)"
      ],
      "metadata": {
        "id": "NqRMmQ38m8oG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ],
      "metadata": {
        "id": "6lCVC3ytnBdS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we create three datasets for training, validation, and test"
      ],
      "metadata": {
        "id": "YU2_dQ5yoPht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "train_dataset = image_dataset_from_directory(new_base_dir / \"train\", image_size=(180, 180), batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(new_base_dir / \"validation\", image_size=(180, 180), batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(new_base_dir / \"test\", image_size=(180, 180), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD4TYNvcoXm5",
        "outputId": "e7b55f12-f171-4141-f916-39fb5c57d6f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "v2-uYhxWgptE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "for size in [32, 64, 128, 256, 512]:\n",
        "    residual = x\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RLs8ivwI1WW",
        "outputId": "d871be08-6f99-4caa-e2fd-8b0a95fe05f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 180, 180, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 180, 180, 3)          0         ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " rescaling_1 (Rescaling)     (None, 180, 180, 3)          0         ['sequential[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 176, 176, 32)         2400      ['rescaling_1[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 176, 176, 32)         128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 176, 176, 32)         0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_10 (Separ  (None, 176, 176, 32)         1312      ['activation_12[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 176, 176, 32)         128       ['separable_conv2d_10[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 176, 176, 32)         0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_11 (Separ  (None, 176, 176, 32)         1312      ['activation_13[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 88, 88, 32)           0         ['separable_conv2d_11[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 88, 88, 32)           1024      ['conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 88, 88, 32)           0         ['max_pooling2d_5[0][0]',     \n",
            "                                                                     'conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 88, 88, 32)           128       ['add_5[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 88, 88, 32)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_12 (Separ  (None, 88, 88, 64)           2336      ['activation_14[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 88, 88, 64)           256       ['separable_conv2d_12[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 88, 88, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_13 (Separ  (None, 88, 88, 64)           4672      ['activation_15[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 44, 44, 64)           0         ['separable_conv2d_13[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 44, 44, 64)           2048      ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 44, 44, 64)           0         ['max_pooling2d_6[0][0]',     \n",
            "                                                                     'conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 44, 44, 64)           256       ['add_6[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 44, 44, 64)           0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_14 (Separ  (None, 44, 44, 128)          8768      ['activation_16[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 44, 44, 128)          512       ['separable_conv2d_14[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 44, 44, 128)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_15 (Separ  (None, 44, 44, 128)          17536     ['activation_17[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 22, 22, 128)          0         ['separable_conv2d_15[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 22, 22, 128)          8192      ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 22, 22, 128)          0         ['max_pooling2d_7[0][0]',     \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 22, 22, 128)          512       ['add_7[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 22, 22, 128)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_16 (Separ  (None, 22, 22, 256)          33920     ['activation_18[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 22, 22, 256)          1024      ['separable_conv2d_16[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 22, 22, 256)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_17 (Separ  (None, 22, 22, 256)          67840     ['activation_19[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 11, 11, 256)          0         ['separable_conv2d_17[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 11, 11, 256)          32768     ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 11, 11, 256)          0         ['max_pooling2d_8[0][0]',     \n",
            "                                                                     'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 11, 11, 256)          1024      ['add_8[0][0]']               \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 11, 11, 256)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_18 (Separ  (None, 11, 11, 512)          133376    ['activation_20[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 11, 11, 512)          2048      ['separable_conv2d_18[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 11, 11, 512)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_19 (Separ  (None, 11, 11, 512)          266752    ['activation_21[0][0]']       \n",
            " ableConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 6, 6, 512)            0         ['separable_conv2d_19[0][0]'] \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 6, 6, 512)            131072    ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 6, 6, 512)            0         ['max_pooling2d_9[0][0]',     \n",
            "                                                                     'conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 512)                  0         ['add_9[0][0]']               \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 512)                  0         ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    513       ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 721857 (2.75 MB)\n",
            "Trainable params: 718849 (2.74 MB)\n",
            "Non-trainable params: 3008 (11.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "uvYuq8MHgEOq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "c7GYPTgIoCD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}