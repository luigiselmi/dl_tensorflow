{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/best_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114d4021-47ab-47da-a6b0-97c944205f50",
      "metadata": {
        "id": "114d4021-47ab-47da-a6b0-97c944205f50"
      },
      "source": [
        "# Best practices\n",
        "In this notebook we'll see how to improve a model's performance by tuning its architecture-level hyperparameters such as:\n",
        "\n",
        "* the number of layers\n",
        "* the number of units, and filters of a layer\n",
        "* the activation function of a layer\n",
        "* the amount of dropout\n",
        "* batch normalization layers\n",
        "* the optimizer and its learning rate\n",
        "\n",
        "The tuning is a search in the hyperparameters space that is much better to do automatically and systematically rather than manually. Keras provides a tool, [KerasTuner](https://keras.io/keras_tuner/getting_started/), to perform the search of the optimal hyperparameters. The tool allows us to set a range of values for each hyperparameter to search for instead of only one. In order to use the tool we have to define a function to build our model and to pass the values of the parameters set by the tool. We start by downloading the tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad9963a2-7a77-4901-8e33-e55262ed110c",
      "metadata": {
        "id": "ad9963a2-7a77-4901-8e33-e55262ed110c",
        "outputId": "a52d9b90-8236-4c54-b5cf-4ff89ce448cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Processing Unit\n",
        "In this notebook we will use a [TPU](https://colab.research.google.com/notebooks/tpu.ipynb). This is not strictly necessary but it will be a test of the Google processing unit to compare with standard CPU or GPU."
      ],
      "metadata": {
        "id": "vHXdskZ9Kfg7"
      },
      "id": "vHXdskZ9Kfg7"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print(f'Running on a TPU w/{tpu.num_accelerators()[\"TPU\"]} cores')\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "Jt5ehLYeF3RE",
        "outputId": "a2c883f1-d394-4194-c7a1-8917ede7c3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Jt5ehLYeF3RE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on a TPU w/8 cores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "AwZJjRoQ-xg5",
        "outputId": "0f744974-302f-491f-acc0-44faf03247aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AwZJjRoQ-xg5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The model-building function\n",
        "We define a function that accept a variable that will be used by the Keras Tuner to pass the hyperparameters to build the model. The model will be created, compiled and returned to be fit with the data. A a first example we define a function to build a model with two fully connected layers and\n",
        "\n",
        "* a variable number of units in the first layer, between 16 and 64, with a step of 16, that is 16, 32, 48, and 64\n",
        "* two different optimizers: rmsprop and adam"
      ],
      "metadata": {
        "id": "sdO2aqgN1nux"
      },
      "id": "sdO2aqgN1nux"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5862a365-340a-4020-b2b4-9eb4899565a9",
      "metadata": {
        "id": "5862a365-340a-4020-b2b4-9eb4899565a9"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(units, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can achieve the same result in a more modular way by subclassing the HyperModel class and overriding the _build()_ function"
      ],
      "metadata": {
        "id": "770TP1s15dKu"
      },
      "id": "770TP1s15dKu"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "class SimpleMLP(kt.HyperModel):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(units, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "\n",
        "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "        return model\n",
        "\n",
        "hypermodel = SimpleMLP(num_classes=10)"
      ],
      "metadata": {
        "id": "SFqP63cd_cwy"
      },
      "id": "SFqP63cd_cwy",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The tuner\n",
        "The hyperparameters search space for our model has 4 * 2 = 8 possible states. The Keras Tuner will build, fit, and assess the performances of the model trying all the possible values of the hyperparameters automatically, and it will finally store the best model in a directory. In our example the tuner will assess the validation accuracy of the models. The tuner can use different algorithms for its search in the hyperparameter space: random search, grid search, Bayesian search, and others.   "
      ],
      "metadata": {
        "id": "4MrFsdnd7Dbn"
      },
      "id": "4MrFsdnd7Dbn"
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10, #100\n",
        "    executions_per_trial=2,\n",
        "    directory=\"mnist_kt_test\",\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bwnXK3Jh_ofu"
      },
      "id": "bwnXK3Jh_ofu",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "Ty_K-cJ2C2Sr",
        "outputId": "924c5ac3-0354-49dc-81ae-76eeee174eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ty_K-cJ2C2Sr",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 2\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking for the best model using the MNIST dataset\n",
        "We look for the best hyperparameters settings for a model that will be used in a classification task with the MNIST dataset. The MNIST dataset is loaded from a URL and the data is kept in the memory available to the VM that execute the notebook. Using the TPU is much faster than a GPU (e.g.: a T4 GPU). The batch size for a TPU should be large in order to use it effectively, e.g. 1024 or more."
      ],
      "metadata": {
        "id": "IHzSyP_rm9Jl"
      },
      "id": "IHzSyP_rm9Jl"
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_train_full = x_train[:]\n",
        "y_train_full = y_train[:]\n",
        "\n",
        "num_val_samples = 10000\n",
        "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
        "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "]\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=num_epochs, # 100\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "t2_4iWrJC7d9",
        "outputId": "12a8bde9-d5a6-4fdb-c587-73d9f57e6000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t2_4iWrJC7d9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 43s]\n",
            "val_accuracy: 0.9751499891281128\n",
            "\n",
            "Best val_accuracy So Far: 0.9762000143527985\n",
            "Total elapsed time: 00h 06m 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best hyperparameters configuration\n",
        "After the hyperparameters search is complete we can use the best model, that with the highest rank. We can retrain it using a higher number of epochs and early stopping to stop the retraining when it starts to overfit. We can select the first 4 set of hyperparamters   "
      ],
      "metadata": {
        "id": "7EwqVAbL-4rC"
      },
      "id": "7EwqVAbL-4rC"
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 4\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)"
      ],
      "metadata": {
        "id": "wSvK6vUTDke4"
      },
      "id": "wSvK6vUTDke4",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best set, index 0, is the set of hyperparameters with the highest accuracy. We can see its hyperparameters"
      ],
      "metadata": {
        "id": "AO92RLRuEQL3"
      },
      "id": "AO92RLRuEQL3"
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = best_hps[0]\n",
        "best_hp.values"
      ],
      "metadata": {
        "id": "bqBLLiY0DXSE",
        "outputId": "d12eeb8f-ab67-49e7-dd53-8a0a4e22cc4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bqBLLiY0DXSE",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 64, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best model retraining\n",
        "We can retrain one or more of the best models using their hypeparameters and a higher number of epochs with early stopping to stop the retraining when it starts to overfit. We can select the first 4 sets of hyperparamters"
      ],
      "metadata": {
        "id": "hCLb198MIluN"
      },
      "id": "hCLb198MIluN"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_epoch(hp):\n",
        "    model = build_model(hp)\n",
        "\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=num_epochs, #100\n",
        "        batch_size=128,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
        "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    return best_epoch"
      ],
      "metadata": {
        "id": "Epthv0OG9fO-"
      },
      "id": "Epthv0OG9fO-",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = get_best_epoch(best_hp)\n",
        "best_epoch"
      ],
      "metadata": {
        "id": "RRUtml-AC4Dd",
        "outputId": "63be12c8-4e5a-4681-f2a6-d6b8a2f3b3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RRUtml-AC4Dd",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 2s 3ms/step - loss: 0.4214 - accuracy: 0.8867 - val_loss: 0.2299 - val_accuracy: 0.9340\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.2157 - accuracy: 0.9383 - val_loss: 0.1801 - val_accuracy: 0.9491\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9518 - val_loss: 0.1554 - val_accuracy: 0.9558\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9610 - val_loss: 0.1326 - val_accuracy: 0.9613\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9667 - val_loss: 0.1158 - val_accuracy: 0.9648\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9716 - val_loss: 0.1124 - val_accuracy: 0.9679\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9748 - val_loss: 0.1056 - val_accuracy: 0.9674\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9777 - val_loss: 0.1021 - val_accuracy: 0.9701\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9794 - val_loss: 0.1044 - val_accuracy: 0.9692\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.9814 - val_loss: 0.0998 - val_accuracy: 0.9701\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9835 - val_loss: 0.0968 - val_accuracy: 0.9710\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9847 - val_loss: 0.0949 - val_accuracy: 0.9712\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9858 - val_loss: 0.0937 - val_accuracy: 0.9721\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 0.0922 - val_accuracy: 0.9740\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0405 - accuracy: 0.9887 - val_loss: 0.0975 - val_accuracy: 0.9722\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0967 - val_accuracy: 0.9743\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.0935 - val_accuracy: 0.9749\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0931 - val_accuracy: 0.9745\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.0917 - val_accuracy: 0.9756\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.0974 - val_accuracy: 0.9746\n",
            "Best epoch: 19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use more epochs for the retraining of the best models and we use the full dataset without the validation set"
      ],
      "metadata": {
        "id": "IYpwwnf7J6LR"
      },
      "id": "IYpwwnf7J6LR"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_trained_model(hp):\n",
        "    best_epoch = get_best_epoch(hp)\n",
        "    model = build_model(hp)\n",
        "    model.fit(\n",
        "        x_train_full, y_train_full,\n",
        "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
        "    return model"
      ],
      "metadata": {
        "id": "1PJeYYkY94aw"
      },
      "id": "1PJeYYkY94aw",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrain the best models"
      ],
      "metadata": {
        "id": "AI2kFWkSJyYQ"
      },
      "id": "AI2kFWkSJyYQ"
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_retrained = []\n",
        "for hp in best_hps:\n",
        "    model = get_best_trained_model(hp)\n",
        "    model.evaluate(x_test, y_test)\n",
        "    best_models_retrained.append(model)"
      ],
      "metadata": {
        "id": "T_X3O8bN-Isl",
        "outputId": "65e96fb5-497d-4231-f552-8d989a4cd48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T_X3O8bN-Isl",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 2s 3ms/step - loss: 0.4276 - accuracy: 0.8857 - val_loss: 0.2387 - val_accuracy: 0.9328\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.2226 - accuracy: 0.9368 - val_loss: 0.1774 - val_accuracy: 0.9507\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1732 - accuracy: 0.9503 - val_loss: 0.1507 - val_accuracy: 0.9594\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1427 - accuracy: 0.9592 - val_loss: 0.1335 - val_accuracy: 0.9613\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1208 - accuracy: 0.9654 - val_loss: 0.1201 - val_accuracy: 0.9666\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1044 - accuracy: 0.9702 - val_loss: 0.1149 - val_accuracy: 0.9660\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9741 - val_loss: 0.1071 - val_accuracy: 0.9683\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9769 - val_loss: 0.1078 - val_accuracy: 0.9688\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9792 - val_loss: 0.0970 - val_accuracy: 0.9701\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9815 - val_loss: 0.0941 - val_accuracy: 0.9717\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9833 - val_loss: 0.1012 - val_accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9841 - val_loss: 0.0882 - val_accuracy: 0.9728\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9857 - val_loss: 0.0937 - val_accuracy: 0.9710\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9874 - val_loss: 0.0890 - val_accuracy: 0.9728\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 0.0876 - val_accuracy: 0.9746\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9897 - val_loss: 0.0918 - val_accuracy: 0.9728\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9901 - val_loss: 0.0934 - val_accuracy: 0.9719\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 0.0896 - val_accuracy: 0.9747\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9919 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0930 - val_accuracy: 0.9727\n",
            "Best epoch: 15\n",
            "Epoch 1/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8951\n",
            "Epoch 2/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9429\n",
            "Epoch 3/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1498 - accuracy: 0.9566\n",
            "Epoch 4/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9644\n",
            "Epoch 5/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9703\n",
            "Epoch 6/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9743\n",
            "Epoch 7/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9780\n",
            "Epoch 8/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9801\n",
            "Epoch 9/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0605 - accuracy: 0.9827\n",
            "Epoch 10/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9845\n",
            "Epoch 11/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9857\n",
            "Epoch 12/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0454 - accuracy: 0.9870\n",
            "Epoch 13/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9884\n",
            "Epoch 14/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9893\n",
            "Epoch 15/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9905\n",
            "Epoch 16/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9909\n",
            "Epoch 17/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9915\n",
            "Epoch 18/18\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9925\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9753\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 2s 3ms/step - loss: 0.4248 - accuracy: 0.8856 - val_loss: 0.2397 - val_accuracy: 0.9346\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.2218 - accuracy: 0.9365 - val_loss: 0.1837 - val_accuracy: 0.9488\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1671 - accuracy: 0.9522 - val_loss: 0.1509 - val_accuracy: 0.9588\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1354 - accuracy: 0.9611 - val_loss: 0.1329 - val_accuracy: 0.9623\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9667 - val_loss: 0.1167 - val_accuracy: 0.9672\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9718 - val_loss: 0.1098 - val_accuracy: 0.9679\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9754 - val_loss: 0.1046 - val_accuracy: 0.9701\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9777 - val_loss: 0.1017 - val_accuracy: 0.9709\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9804 - val_loss: 0.0983 - val_accuracy: 0.9714\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9826 - val_loss: 0.0958 - val_accuracy: 0.9730\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9845 - val_loss: 0.0971 - val_accuracy: 0.9713\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9859 - val_loss: 0.0926 - val_accuracy: 0.9730\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.9874 - val_loss: 0.0894 - val_accuracy: 0.9738\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9884 - val_loss: 0.0887 - val_accuracy: 0.9725\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9891 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.0917 - val_accuracy: 0.9749\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9914 - val_loss: 0.0935 - val_accuracy: 0.9744\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.0933 - val_accuracy: 0.9745\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.0972 - val_accuracy: 0.9740\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0907 - val_accuracy: 0.9748\n",
            "Best epoch: 14\n",
            "Epoch 1/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3965 - accuracy: 0.8936\n",
            "Epoch 2/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2035 - accuracy: 0.9415\n",
            "Epoch 3/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1514 - accuracy: 0.9563\n",
            "Epoch 4/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1224 - accuracy: 0.9645\n",
            "Epoch 5/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.9701\n",
            "Epoch 6/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9734\n",
            "Epoch 7/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9767\n",
            "Epoch 8/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9795\n",
            "Epoch 9/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9819\n",
            "Epoch 10/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9833\n",
            "Epoch 11/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9849\n",
            "Epoch 12/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.9863\n",
            "Epoch 13/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9878\n",
            "Epoch 14/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.9890\n",
            "Epoch 15/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9893\n",
            "Epoch 16/16\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9900\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9771\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.4206 - accuracy: 0.8864 - val_loss: 0.2323 - val_accuracy: 0.9356\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 2ms/step - loss: 0.2166 - accuracy: 0.9376 - val_loss: 0.1809 - val_accuracy: 0.9507\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9510 - val_loss: 0.1526 - val_accuracy: 0.9590\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1405 - accuracy: 0.9593 - val_loss: 0.1373 - val_accuracy: 0.9625\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1197 - accuracy: 0.9648 - val_loss: 0.1291 - val_accuracy: 0.9626\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9698 - val_loss: 0.1137 - val_accuracy: 0.9676\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9733 - val_loss: 0.1158 - val_accuracy: 0.9653\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0832 - accuracy: 0.9760 - val_loss: 0.1068 - val_accuracy: 0.9677\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9782 - val_loss: 0.1136 - val_accuracy: 0.9665\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9807 - val_loss: 0.1041 - val_accuracy: 0.9711\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.1065 - val_accuracy: 0.9688\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9836 - val_loss: 0.0997 - val_accuracy: 0.9700\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9858 - val_loss: 0.0976 - val_accuracy: 0.9708\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0485 - accuracy: 0.9861 - val_loss: 0.0989 - val_accuracy: 0.9711\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 0.0967 - val_accuracy: 0.9728\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0990 - val_accuracy: 0.9718\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9891 - val_loss: 0.0977 - val_accuracy: 0.9716\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.0963 - val_accuracy: 0.9718\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.1054 - val_accuracy: 0.9699\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9920 - val_loss: 0.0986 - val_accuracy: 0.9727\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8943\n",
            "Epoch 2/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9416\n",
            "Epoch 3/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1583 - accuracy: 0.9538\n",
            "Epoch 4/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9624\n",
            "Epoch 5/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1111 - accuracy: 0.9679\n",
            "Epoch 6/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9720\n",
            "Epoch 7/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9756\n",
            "Epoch 8/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.9780\n",
            "Epoch 9/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9805\n",
            "Epoch 10/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9820\n",
            "Epoch 11/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9834\n",
            "Epoch 12/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9847\n",
            "Epoch 13/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9862\n",
            "Epoch 14/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9875\n",
            "Epoch 15/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9889\n",
            "Epoch 16/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9897\n",
            "Epoch 17/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0341 - accuracy: 0.9903\n",
            "Epoch 18/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9913\n",
            "Epoch 19/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9919\n",
            "Epoch 20/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9926\n",
            "Epoch 21/21\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9936\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9761\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 2s 3ms/step - loss: 0.4265 - accuracy: 0.8871 - val_loss: 0.2316 - val_accuracy: 0.9373\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.2148 - accuracy: 0.9386 - val_loss: 0.1779 - val_accuracy: 0.9488\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9527 - val_loss: 0.1485 - val_accuracy: 0.9587\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9611 - val_loss: 0.1315 - val_accuracy: 0.9648\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1129 - accuracy: 0.9673 - val_loss: 0.1199 - val_accuracy: 0.9651\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9720 - val_loss: 0.1125 - val_accuracy: 0.9685\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9752 - val_loss: 0.1058 - val_accuracy: 0.9708\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0768 - accuracy: 0.9776 - val_loss: 0.1058 - val_accuracy: 0.9685\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9794 - val_loss: 0.0998 - val_accuracy: 0.9724\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9819 - val_loss: 0.1017 - val_accuracy: 0.9708\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 0.0941 - val_accuracy: 0.9740\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9857 - val_loss: 0.0899 - val_accuracy: 0.9753\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0982 - val_accuracy: 0.9725\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 0.1001 - val_accuracy: 0.9719\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9889 - val_loss: 0.0946 - val_accuracy: 0.9742\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 0.0989 - val_accuracy: 0.9728\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.0931 - val_accuracy: 0.9738\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.0999 - val_accuracy: 0.9728\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9927 - val_loss: 0.0937 - val_accuracy: 0.9738\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.0957 - val_accuracy: 0.9749\n",
            "Best epoch: 12\n",
            "Epoch 1/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.8956\n",
            "Epoch 2/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.9445\n",
            "Epoch 3/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1480 - accuracy: 0.9576\n",
            "Epoch 4/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9659\n",
            "Epoch 5/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9712\n",
            "Epoch 6/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9750\n",
            "Epoch 7/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9779\n",
            "Epoch 8/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.9809\n",
            "Epoch 9/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9825\n",
            "Epoch 10/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9843\n",
            "Epoch 11/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9855\n",
            "Epoch 12/14\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9868\n",
            "Epoch 13/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9878\n",
            "Epoch 14/14\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9888\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_retrained = best_models_retrained[0]\n",
        "best_model_retrained.summary()"
      ],
      "metadata": {
        "id": "ktlUXJ5v-S5Y",
        "outputId": "dc591be1-3207-45f7-a9a3-31c008857693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ktlUXJ5v-S5Y",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50890 (198.79 KB)\n",
            "Trainable params: 50890 (198.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we do not want to retrain the best models we can simply get them from the tuner"
      ],
      "metadata": {
        "id": "e7DCpWAlLIZb"
      },
      "id": "e7DCpWAlLIZb"
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = tuner.get_best_models(top_n)\n",
        "len(best_models)"
      ],
      "metadata": {
        "id": "XbZgAne5IZep",
        "outputId": "969f4aa6-35e8-4ee1-fdfd-4b3b3ce91d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XbZgAne5IZep",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXAJaZ08Rt0f"
      },
      "id": "gXAJaZ08Rt0f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}