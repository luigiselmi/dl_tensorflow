{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/best_practices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114d4021-47ab-47da-a6b0-97c944205f50",
      "metadata": {
        "id": "114d4021-47ab-47da-a6b0-97c944205f50"
      },
      "source": [
        "# Best practices\n",
        "In this notebook we'll see how to improve a model's performance by tuning its architecture-level hyperparameters such as:\n",
        "\n",
        "* the number of layers\n",
        "* the number of units, and filters of a layer\n",
        "* the activation function of a layer\n",
        "* the amount of dropout\n",
        "* batch normalization layers\n",
        "* the optimizer and its learning rate\n",
        "\n",
        "The tuning is a search in the hyperparameters space that is much better to do automatically and systematically rather than manually. Keras provides a tool, [KerasTuner](https://keras.io/keras_tuner/getting_started/), to perform the search of the optimal hyperparameters. The tool allows us to set a range of values for each hyperparameter to search for instead of only one. In order to use the tool we have to define a function to build our model and to pass the values of the parameters set by the tool. We start by downloading the tool."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "AwZJjRoQ-xg5",
        "outputId": "3334423a-f2bb-4f98-e078-0ab57e93f9fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AwZJjRoQ-xg5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ad9963a2-7a77-4901-8e33-e55262ed110c",
      "metadata": {
        "id": "ad9963a2-7a77-4901-8e33-e55262ed110c"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The model-building function\n",
        "We define a function that accept a variable that will be used by the Keras Tuner to pass the hyperparameters to build the model. The model will be created, compiled and returned to be fit with the data. A a first example we define a function to build a model with two fully connected layers and\n",
        "\n",
        "* a variable number of units in the first layer, between 16 and 64, with a step of 16, that is 16, 32, 48, and 64\n",
        "* two different optimizers: rmsprop and adam"
      ],
      "metadata": {
        "id": "sdO2aqgN1nux"
      },
      "id": "sdO2aqgN1nux"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5862a365-340a-4020-b2b4-9eb4899565a9",
      "metadata": {
        "id": "5862a365-340a-4020-b2b4-9eb4899565a9"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(units, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can achieve the same result in a more modular way by subclassing the HyperModel class and overriding the _build()_ function"
      ],
      "metadata": {
        "id": "770TP1s15dKu"
      },
      "id": "770TP1s15dKu"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "class SimpleMLP(kt.HyperModel):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(units, activation=\"relu\"),\n",
        "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
        "        ])\n",
        "\n",
        "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "        return model\n",
        "\n",
        "hypermodel = SimpleMLP(num_classes=10)"
      ],
      "metadata": {
        "id": "SFqP63cd_cwy"
      },
      "id": "SFqP63cd_cwy",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The tuner\n",
        "The hyperparameters search space for our model has 4 * 2 = 8 possible states. The Keras Tuner will build, fit, and assess the performances of the model trying all the possible values of the hyperparameters automatically, and it will finally store the best model in a directory. In our example the tuner will assess the validation accuracy of the models. The tuner can use different algorithms for its search in the hyperparameter space: random search, grid search, Bayesian search, and others.   "
      ],
      "metadata": {
        "id": "4MrFsdnd7Dbn"
      },
      "id": "4MrFsdnd7Dbn"
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10, #100\n",
        "    executions_per_trial=2,\n",
        "    directory=\"mnist_kt_test\",\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bwnXK3Jh_ofu"
      },
      "id": "bwnXK3Jh_ofu",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "Ty_K-cJ2C2Sr",
        "outputId": "e2c0b289-f0c4-40ec-a220-6f7bedd73802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ty_K-cJ2C2Sr",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 2\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "optimizer (Choice)\n",
            "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking for the best model using the MNIST dataset\n",
        "We look for the best hyperparameters settings for a model that will be used in a classification task with the MNIST dataset"
      ],
      "metadata": {
        "id": "IHzSyP_rm9Jl"
      },
      "id": "IHzSyP_rm9Jl"
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
        "x_train_full = x_train[:]\n",
        "y_train_full = y_train[:]\n",
        "\n",
        "num_val_samples = 10000\n",
        "x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
        "y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
        "]\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=num_epochs, # 100\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "t2_4iWrJC7d9",
        "outputId": "74db6c63-b0f6-4826-818e-073368ffdee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t2_4iWrJC7d9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 00m 46s]\n",
            "val_accuracy: 0.9749000072479248\n",
            "\n",
            "Best val_accuracy So Far: 0.9772000014781952\n",
            "Total elapsed time: 01h 18m 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best hyperparameters configuration\n",
        "After the hyperparameters search is complete we can use the best model, that with the highest rank. We can retrain it using a higher number of epochs and early stopping to stop the retraining when it starts to overfit. We can select the first 4 set of hyperparamters   "
      ],
      "metadata": {
        "id": "7EwqVAbL-4rC"
      },
      "id": "7EwqVAbL-4rC"
    },
    {
      "cell_type": "code",
      "source": [
        "top_n = 4\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)"
      ],
      "metadata": {
        "id": "wSvK6vUTDke4"
      },
      "id": "wSvK6vUTDke4",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best set, index 0, is the set of hyperparameters with the highest accuracy. We can see its hyperparameters"
      ],
      "metadata": {
        "id": "AO92RLRuEQL3"
      },
      "id": "AO92RLRuEQL3"
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = best_hps[0]\n",
        "best_hp.values"
      ],
      "metadata": {
        "id": "bqBLLiY0DXSE",
        "outputId": "0dd9221e-c947-4ab9-ee47-2249d611058e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bqBLLiY0DXSE",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': 64, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best model retraining\n",
        "We can retrain one or more of the best models using their hypeparameters and a higher number of epochs with early stopping to stop the retraining when it starts to overfit. We can select the first 4 sets of hyperparamters"
      ],
      "metadata": {
        "id": "hCLb198MIluN"
      },
      "id": "hCLb198MIluN"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_epoch(hp):\n",
        "    model = build_model(hp)\n",
        "\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", mode=\"min\", patience=10)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=num_epochs, #100\n",
        "        batch_size=128,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
        "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
        "    print(f\"Best epoch: {best_epoch}\")\n",
        "    return best_epoch"
      ],
      "metadata": {
        "id": "Epthv0OG9fO-"
      },
      "id": "Epthv0OG9fO-",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = get_best_epoch(hp)\n",
        "best_epoch"
      ],
      "metadata": {
        "id": "RRUtml-AC4Dd",
        "outputId": "ffd10a2c-f206-489f-aca7-39002373f5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RRUtml-AC4Dd",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.7125 - val_accuracy: 0.9317 - val_loss: 0.2355\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2288 - val_accuracy: 0.9515 - val_loss: 0.1739\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1720 - val_accuracy: 0.9580 - val_loss: 0.1481\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1398 - val_accuracy: 0.9639 - val_loss: 0.1275\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.1143 - val_accuracy: 0.9638 - val_loss: 0.1214\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0988 - val_accuracy: 0.9672 - val_loss: 0.1089\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0851 - val_accuracy: 0.9670 - val_loss: 0.1087\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0746 - val_accuracy: 0.9679 - val_loss: 0.1046\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0679 - val_accuracy: 0.9709 - val_loss: 0.0961\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0618 - val_accuracy: 0.9700 - val_loss: 0.0975\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0540 - val_accuracy: 0.9704 - val_loss: 0.1017\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0522 - val_accuracy: 0.9713 - val_loss: 0.0915\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0463 - val_accuracy: 0.9723 - val_loss: 0.0967\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0419 - val_accuracy: 0.9722 - val_loss: 0.0970\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0389 - val_accuracy: 0.9726 - val_loss: 0.0936\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0359 - val_accuracy: 0.9723 - val_loss: 0.0919\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0364 - val_accuracy: 0.9744 - val_loss: 0.0906\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0305 - val_accuracy: 0.9719 - val_loss: 0.0959\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0291 - val_accuracy: 0.9722 - val_loss: 0.0952\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0263 - val_accuracy: 0.9742 - val_loss: 0.0956\n",
            "Best epoch: 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use more epochs for the retraining of the best models and we use the full dataset without the validation set"
      ],
      "metadata": {
        "id": "IYpwwnf7J6LR"
      },
      "id": "IYpwwnf7J6LR"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_trained_model(hp):\n",
        "    best_epoch = get_best_epoch(hp)\n",
        "    model = build_model(hp)\n",
        "    model.fit(\n",
        "        x_train_full, y_train_full,\n",
        "        batch_size=128, epochs=int(best_epoch * 1.2))\n",
        "    return model"
      ],
      "metadata": {
        "id": "1PJeYYkY94aw"
      },
      "id": "1PJeYYkY94aw",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrain the best models"
      ],
      "metadata": {
        "id": "AI2kFWkSJyYQ"
      },
      "id": "AI2kFWkSJyYQ"
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_retrained = []\n",
        "for hp in best_hps:\n",
        "    model = get_best_trained_model(hp)\n",
        "    model.evaluate(x_test, y_test)\n",
        "    best_models_retrained.append(model)"
      ],
      "metadata": {
        "id": "T_X3O8bN-Isl",
        "outputId": "f21b52e5-fab1-4bf6-8c03-f905cded34ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T_X3O8bN-Isl",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.6804 - val_accuracy: 0.9386 - val_loss: 0.2289\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2225 - val_accuracy: 0.9499 - val_loss: 0.1778\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1733 - val_accuracy: 0.9603 - val_loss: 0.1494\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1377 - val_accuracy: 0.9637 - val_loss: 0.1339\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1153 - val_accuracy: 0.9658 - val_loss: 0.1237\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0999 - val_accuracy: 0.9654 - val_loss: 0.1157\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0899 - val_accuracy: 0.9685 - val_loss: 0.1083\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0768 - val_accuracy: 0.9705 - val_loss: 0.1043\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0678 - val_accuracy: 0.9714 - val_loss: 0.0997\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0630 - val_accuracy: 0.9718 - val_loss: 0.1004\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0577 - val_accuracy: 0.9730 - val_loss: 0.0959\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0515 - val_accuracy: 0.9731 - val_loss: 0.0925\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0446 - val_accuracy: 0.9722 - val_loss: 0.0981\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0417 - val_accuracy: 0.9719 - val_loss: 0.0951\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0397 - val_accuracy: 0.9696 - val_loss: 0.1062\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0362 - val_accuracy: 0.9721 - val_loss: 0.0992\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0340 - val_accuracy: 0.9722 - val_loss: 0.0983\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0292 - val_accuracy: 0.9724 - val_loss: 0.0981\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0280 - val_accuracy: 0.9734 - val_loss: 0.0958\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0254 - val_accuracy: 0.9738 - val_loss: 0.0991\n",
            "Best epoch: 12\n",
            "Epoch 1/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.6350\n",
            "Epoch 2/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2094\n",
            "Epoch 3/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1568\n",
            "Epoch 4/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1264\n",
            "Epoch 5/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1084\n",
            "Epoch 6/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.0947\n",
            "Epoch 7/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9777 - loss: 0.0780\n",
            "Epoch 8/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0732\n",
            "Epoch 9/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0641\n",
            "Epoch 10/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0597\n",
            "Epoch 11/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0519\n",
            "Epoch 12/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0484\n",
            "Epoch 13/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0442\n",
            "Epoch 14/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0400\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.1029\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.7825 - val_accuracy: 0.9335 - val_loss: 0.2399\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.2295 - val_accuracy: 0.9505 - val_loss: 0.1812\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1727 - val_accuracy: 0.9568 - val_loss: 0.1531\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1429 - val_accuracy: 0.9607 - val_loss: 0.1353\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1209 - val_accuracy: 0.9649 - val_loss: 0.1233\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.1033 - val_accuracy: 0.9660 - val_loss: 0.1162\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0886 - val_accuracy: 0.9682 - val_loss: 0.1078\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0791 - val_accuracy: 0.9699 - val_loss: 0.1070\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0727 - val_accuracy: 0.9682 - val_loss: 0.1077\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0645 - val_accuracy: 0.9693 - val_loss: 0.1024\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0572 - val_accuracy: 0.9716 - val_loss: 0.0962\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0508 - val_accuracy: 0.9694 - val_loss: 0.1003\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0463 - val_accuracy: 0.9721 - val_loss: 0.0928\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0423 - val_accuracy: 0.9729 - val_loss: 0.0909\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0374 - val_accuracy: 0.9716 - val_loss: 0.0947\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0348 - val_accuracy: 0.9742 - val_loss: 0.0900\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0292 - val_accuracy: 0.9728 - val_loss: 0.0922\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0283 - val_accuracy: 0.9720 - val_loss: 0.0987\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0244 - val_accuracy: 0.9741 - val_loss: 0.0919\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0226 - val_accuracy: 0.9733 - val_loss: 0.0941\n",
            "Best epoch: 16\n",
            "Epoch 1/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.7212\n",
            "Epoch 2/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.2266\n",
            "Epoch 3/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1664\n",
            "Epoch 4/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1341\n",
            "Epoch 5/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1100\n",
            "Epoch 6/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.0936\n",
            "Epoch 7/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0815\n",
            "Epoch 8/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0705\n",
            "Epoch 9/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0605\n",
            "Epoch 10/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0557\n",
            "Epoch 11/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0483\n",
            "Epoch 12/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0448\n",
            "Epoch 13/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0381\n",
            "Epoch 14/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0354\n",
            "Epoch 15/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0329\n",
            "Epoch 16/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0287\n",
            "Epoch 17/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0256\n",
            "Epoch 18/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0228\n",
            "Epoch 19/19\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0204\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1012\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.6874 - val_accuracy: 0.9312 - val_loss: 0.2393\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2375 - val_accuracy: 0.9501 - val_loss: 0.1825\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1795 - val_accuracy: 0.9593 - val_loss: 0.1531\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1399 - val_accuracy: 0.9598 - val_loss: 0.1430\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1224 - val_accuracy: 0.9669 - val_loss: 0.1197\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.1035 - val_accuracy: 0.9685 - val_loss: 0.1121\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0878 - val_accuracy: 0.9688 - val_loss: 0.1108\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0787 - val_accuracy: 0.9708 - val_loss: 0.1052\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0701 - val_accuracy: 0.9714 - val_loss: 0.1003\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0629 - val_accuracy: 0.9716 - val_loss: 0.0992\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0572 - val_accuracy: 0.9721 - val_loss: 0.0982\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0513 - val_accuracy: 0.9732 - val_loss: 0.0940\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0456 - val_accuracy: 0.9720 - val_loss: 0.0966\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0445 - val_accuracy: 0.9741 - val_loss: 0.0943\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0393 - val_accuracy: 0.9720 - val_loss: 0.1033\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0346 - val_accuracy: 0.9744 - val_loss: 0.0974\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0312 - val_accuracy: 0.9728 - val_loss: 0.1013\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0308 - val_accuracy: 0.9736 - val_loss: 0.0967\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0271 - val_accuracy: 0.9727 - val_loss: 0.1003\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0262 - val_accuracy: 0.9739 - val_loss: 0.0949\n",
            "Best epoch: 12\n",
            "Epoch 1/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.6481\n",
            "Epoch 2/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.2299\n",
            "Epoch 3/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1661\n",
            "Epoch 4/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1393\n",
            "Epoch 5/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1169\n",
            "Epoch 6/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.1022\n",
            "Epoch 7/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.0886\n",
            "Epoch 8/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0782\n",
            "Epoch 9/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0745\n",
            "Epoch 10/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0637\n",
            "Epoch 11/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0571\n",
            "Epoch 12/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0562\n",
            "Epoch 13/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0504\n",
            "Epoch 14/14\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0457\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.1122\n",
            "Epoch 1/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.6789 - val_accuracy: 0.9287 - val_loss: 0.2434\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.2255 - val_accuracy: 0.9490 - val_loss: 0.1842\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1732 - val_accuracy: 0.9600 - val_loss: 0.1488\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1384 - val_accuracy: 0.9611 - val_loss: 0.1330\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1162 - val_accuracy: 0.9654 - val_loss: 0.1218\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.1015 - val_accuracy: 0.9677 - val_loss: 0.1103\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0860 - val_accuracy: 0.9708 - val_loss: 0.1014\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0754 - val_accuracy: 0.9703 - val_loss: 0.0999\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0705 - val_accuracy: 0.9713 - val_loss: 0.0967\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0643 - val_accuracy: 0.9739 - val_loss: 0.0919\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0576 - val_accuracy: 0.9727 - val_loss: 0.0948\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0503 - val_accuracy: 0.9742 - val_loss: 0.0893\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0462 - val_accuracy: 0.9739 - val_loss: 0.0890\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0434 - val_accuracy: 0.9754 - val_loss: 0.0879\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0399 - val_accuracy: 0.9740 - val_loss: 0.0901\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0348 - val_accuracy: 0.9753 - val_loss: 0.0913\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0344 - val_accuracy: 0.9761 - val_loss: 0.0886\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0296 - val_accuracy: 0.9764 - val_loss: 0.0879\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0282 - val_accuracy: 0.9753 - val_loss: 0.0926\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0250 - val_accuracy: 0.9765 - val_loss: 0.0923\n",
            "Best epoch: 18\n",
            "Epoch 1/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.6442\n",
            "Epoch 2/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2230\n",
            "Epoch 3/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1658\n",
            "Epoch 4/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1333\n",
            "Epoch 5/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.1027\n",
            "Epoch 6/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0884\n",
            "Epoch 7/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0785\n",
            "Epoch 8/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0713\n",
            "Epoch 9/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0635\n",
            "Epoch 10/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0599\n",
            "Epoch 11/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0542\n",
            "Epoch 12/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0479\n",
            "Epoch 13/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0471\n",
            "Epoch 14/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0427\n",
            "Epoch 15/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0377\n",
            "Epoch 16/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0347\n",
            "Epoch 17/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9912 - loss: 0.0324\n",
            "Epoch 18/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0312\n",
            "Epoch 19/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0264\n",
            "Epoch 20/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0271\n",
            "Epoch 21/21\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0274\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.1032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_retrained = best_models_retrained[0]\n",
        "best_model_retrained.summary()"
      ],
      "metadata": {
        "id": "ktlUXJ5v-S5Y",
        "outputId": "b758d70e-fa9b-4b20-c25f-8a21eafb7470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "id": "ktlUXJ5v-S5Y",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m50,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,782\u001b[0m (397.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,782</span> (397.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m50,892\u001b[0m (198.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,892</span> (198.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we do not want to retrain the best models we can simply get them from the tuner"
      ],
      "metadata": {
        "id": "e7DCpWAlLIZb"
      },
      "id": "e7DCpWAlLIZb"
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = tuner.get_best_models(top_n)"
      ],
      "metadata": {
        "id": "XbZgAne5IZep",
        "outputId": "b56d15ba-9ad4-4865-adcd-5d92903c8d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XbZgAne5IZep",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXAJaZ08Rt0f"
      },
      "id": "gXAJaZ08Rt0f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}