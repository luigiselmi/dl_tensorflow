{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4RrwQI7OW6MGx636G2qmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision\n",
        "We have already seen the application of fully connected neural networks to the MNIST digits images classification task. In this notebook we use convolutional neural networks for the same task that provides several advantages over the fully connected layers."
      ],
      "metadata": {
        "id": "9Iq5xoKJrFZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rTbu5a0mq5c0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The MNIST digits classification task\n",
        "We use the functional syntax to build our convolutional model. We use three convolutional layers, followed by a max pooling layer, then a flatten layer, that is a fully connected layer of one dimension with the same number of units as the size of the last convolutional layer. The flatten layer is used to reduce the output to one dimension. Finally we have a fully connected layer with a softmax activation function to provide the probability for each digit. As we can see from the model summary, the size of the model's features, i.e. width and heigh, shrinks while the number of channels, or feature maps, increases. The shape of the inputs is Height x Width x Channel, in the MNIST case 28 x 28 x 1.  "
      ],
      "metadata": {
        "id": "Li5iGocnvlT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thoiAxPLv-xE",
        "outputId": "8f295e94-8e91-4fb5-f40c-d36d83492e3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                11530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104202 (407.04 KB)\n",
            "Trainable params: 104202 (407.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We reuse most of the code used for the MNIST digits classification in the notebook [Machine Learning Fundamentals](ml_fundamentals.ipynb) with the fully connected layers."
      ],
      "metadata": {
        "id": "FBvBNMqrdy61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ul2mehJv_-C",
        "outputId": "aa79568a-bdde-4271-b9f7-a73ea09fd120"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compile and fit the CNN model  "
      ],
      "metadata": {
        "id": "fas_cf6GkrYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzayy0qLd9Ot",
        "outputId": "4ca5f3df-0427-4cc5-e441-ffe8647c79d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 57s 59ms/step - loss: 0.1615 - accuracy: 0.9504\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 56s 59ms/step - loss: 0.0433 - accuracy: 0.9863\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 55s 59ms/step - loss: 0.0307 - accuracy: 0.9907\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 56s 60ms/step - loss: 0.0225 - accuracy: 0.9931\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 55s 59ms/step - loss: 0.0176 - accuracy: 0.9946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x792256251930>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform an evaluation of the model's performances on the test set. We can see the our network with only three convolutional layers achieves a better performance than the fully connected model."
      ],
      "metadata": {
        "id": "ZkwEskZ8lnFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTnpjBIKidsb",
        "outputId": "42929a6f-17f6-41e5-bb82-cf2a688726f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0205 - accuracy: 0.9942\n",
            "Test accuracy: 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The convolution operation\n",
        "The difference between a dense layer and a convolutional layer is that a dense (fully connected) layer learns global patterns in an image, while a convolutional layer learns local patterns within small 2D windows that do not depend on their location in the image. In our convolutional layers we have used a window of size 3x3 pixels (kernel size). The advantages of using convolutional layers is that they learn patterns that are\n",
        "\n",
        "* translational invariant\n",
        "* hierarchically organized\n",
        "\n",
        "An object can be learnt by the convolutional layer as made up of simpler objects such as circles and lines, wherever they appear in the same configuration. A convolutional layer is defined by its\n",
        "\n",
        "* window (or kernel) size\n",
        "* number of filters (or channels / feature maps)\n",
        "\n",
        "Each kernel of size K x K is learnt so that the number of parameters to be learnt by a convolutional layer depends on the kernel size, the number of filters, and the way the kernel is moved over the feature maps, that is the padding and the stride.  "
      ],
      "metadata": {
        "id": "jp_lJDr4nnND"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3j_Z-Jsskm2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}