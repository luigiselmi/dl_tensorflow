{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODSDLWhCB3+dMPBWaHFahP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiselmi/dl_tensorflow/blob/main/computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision\n",
        "We have already seen the application of fully connected neural networks to the MNIST digits images classification task. In this notebook we use convolutional neural networks for the same task that provides several advantages over the fully connected layers."
      ],
      "metadata": {
        "id": "9Iq5xoKJrFZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rTbu5a0mq5c0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The MNIST digits classification task\n",
        "We use the functional syntax to build our convolutional model. We use three convolutional layers, followed by a max pooling layer, then a flatten layer, that is a fully connected layer of one dimension with the same number of units as the size of the last convolutional layer. The flatten layer is used to reduce the output to one dimension. Finally we have a fully connected layer with a softmax activation function to provide the probability for each digit. As we can see from the model summary, the size of the model's features, i.e. width and heigh, shrinks while the number of channels, or feature maps, increases. The shape of the inputs is Height x Width x Channel, in the MNIST case 28 x 28 x 1.  \n",
        "\n",
        "![ConvNet](https://github.com/luigiselmi/dl_tensorflow/blob/main/images/mnist_cnn.jpg?raw=1)"
      ],
      "metadata": {
        "id": "Li5iGocnvlT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thoiAxPLv-xE",
        "outputId": "5613da97-d1d6-4c84-dd70-5602e693ffed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                11530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104202 (407.04 KB)\n",
            "Trainable params: 104202 (407.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We reuse most of the code used for the MNIST digits classification in the notebook [Machine Learning Fundamentals](ml_fundamentals.ipynb) with the fully connected layers."
      ],
      "metadata": {
        "id": "FBvBNMqrdy61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ul2mehJv_-C",
        "outputId": "8bd0bcfd-d43d-4bb3-bd66-7e77852ad100"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compile and fit the CNN model  "
      ],
      "metadata": {
        "id": "fas_cf6GkrYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzayy0qLd9Ot",
        "outputId": "19f272cf-7694-426b-e337-b0b814f4bdb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 52s 54ms/step - loss: 0.1616 - accuracy: 0.9504\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0437 - accuracy: 0.9862\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 48s 51ms/step - loss: 0.0312 - accuracy: 0.9902\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.0227 - accuracy: 0.9929\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 48s 51ms/step - loss: 0.0182 - accuracy: 0.9945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb9f6785ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform an evaluation of the model's performances on the test set. We can see the our network with only three convolutional layers achieves a better performance than the fully connected model."
      ],
      "metadata": {
        "id": "ZkwEskZ8lnFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTnpjBIKidsb",
        "outputId": "42929a6f-17f6-41e5-bb82-cf2a688726f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0205 - accuracy: 0.9942\n",
            "Test accuracy: 0.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The convolution operation\n",
        "The difference between a dense layer and a convolutional layer is that a dense (fully connected) layer learns global patterns in an image, while a convolutional layer learns local patterns within small 2D windows that do not depend on their location in the image. In our convolutional layers we have used a window of size 3x3 pixels (kernel size). The advantages of using convolutional layers is that they learn patterns that are\n",
        "\n",
        "* translational invariant\n",
        "* hierarchically organized\n",
        "\n",
        "An object can be learnt by the convolutional layer as made up of simpler objects such as circles and lines, wherever they appear in the same configuration. A convolutional layer is defined by its\n",
        "\n",
        "* window (or kernel) size\n",
        "* number of filters (or channels / feature maps)\n",
        "\n",
        "The number of parameters to be learnt by a convolutional layer depends on the kernel size, the number of filters, and the way the kernel is moved over the input, that is the padding and the stride. Padding is used to add one or more rows and columns to the borders of the 2D input in order to have an output of the same size of the input. Stride is used to reduce the size of the output."
      ],
      "metadata": {
        "id": "jp_lJDr4nnND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The max-pooling operation\n",
        "After a convolutional layer a max-pooling layer is used to halve the size of feature maps. There are no learning parameters for this type of layer sine it is a simple operation for which the maximum value of a 2x2 kernel with stride 2 is used to build the output. The main effect of max-pooling is to reduce the number of feature maps and therefore the number of parameters to learn."
      ],
      "metadata": {
        "id": "q6BEcdbBNosV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of learnable parameters of each convolutional layer\n",
        "The number of parameters $p_l$ to learn by each convolutional layer $l$ is given by the product of the number of feauture maps of the previous layer $f_{l-1}$ (max-pooling) times the kernel size (eg. 3 x 3 = 9) times the number of output feature maps $f_l$ of the convolutional layer plus again the number of feature maps $f_l$:\n",
        "\n",
        "$$p_l = f_{l-1} × k_l × k_l × f_l + f_l  $$\n",
        "\n",
        "For instance, the number of parameters of the 2nd convolutional layer is\n",
        "\n",
        "$$p_2 = f_1 × 3 × 3 × f_2 + f_2 = 32 × 3 × 3 \\times 64 + 64 = 18496$$\n",
        "\n",
        "The number of parameters of the 3rd convolutional layer is\n",
        "\n",
        "$$p_3 = f_2 × 3 × 3 × f_3 + f_3 = 64 × 3 × 3 \\times 128 + 128 = 73856$$"
      ],
      "metadata": {
        "id": "adbc_fweSOOy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3j_Z-Jsskm2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}